{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com/' \n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"d1f3b08e786e50ea9fe990e07e52d6c1\", element=\"bb72b26e-c03d-4cfb-a858-c3cebb076d77\")>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobsearch = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "jobsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobsearch.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = driver.find_element_by_id('qsb-location-sugg')\n",
    "location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element_by_class_name('btn')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "company = []\n",
    "locations = []\n",
    "xp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "title_tag = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "company_tag = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "location_tag = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")\n",
    "xp_tag = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in title_tag:\n",
    "    job_title.append(i.text)\n",
    "for c in company_tag:\n",
    "    company.append(c.text)\n",
    "company\n",
    "for l in location_tag:\n",
    "    locations.append(l.text)\n",
    "for x in xp_tag:\n",
    "    xp.append(x.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing in JobDF Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "JobDF = pd.DataFrame({\"Job Title\":job_title[0:10],\"Company\":company[0:10],\"Experience\":xp[0:10],\"Location\":locations[0:10]})\n",
    "JobDF.reset_index(drop=True,inplace = True)\n",
    "JobDF.index+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>RANDSTAD INDIA PVT LTD</td>\n",
       "      <td>8-12 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Openings For Data Analyst</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst / Business Analyst (Demand Planning)</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Business Analyst/Data Analyst</td>\n",
       "      <td>Telamon HR Solutions</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Business Cum Data Analyst</td>\n",
       "      <td>Virtusa Consulting Services Pvt Ltd</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job Title  \\\n",
       "1                               Business Data Analyst   \n",
       "2                                 Senior Data Analyst   \n",
       "3                                 Senior Data Analyst   \n",
       "4                                 Senior Data Analyst   \n",
       "5                                 Senior Data Analyst   \n",
       "6                           Openings For Data Analyst   \n",
       "7   Data Analyst / Business Analyst (Demand Planning)   \n",
       "8                                        Data Analyst   \n",
       "9                       Business Analyst/Data Analyst   \n",
       "10                          Business Cum Data Analyst   \n",
       "\n",
       "                                Company Experience  \\\n",
       "1                RANDSTAD INDIA PVT LTD   8-12 Yrs   \n",
       "2     Flipkart Internet Private Limited    2-5 Yrs   \n",
       "3     Flipkart Internet Private Limited    3-7 Yrs   \n",
       "4     Flipkart Internet Private Limited    3-7 Yrs   \n",
       "5     Flipkart Internet Private Limited    3-7 Yrs   \n",
       "6      Allegis Services India Pvt. Ltd.    0-3 Yrs   \n",
       "7                              Flipkart    1-4 Yrs   \n",
       "8                     Applied Materials    0-3 Yrs   \n",
       "9                  Telamon HR Solutions    3-5 Yrs   \n",
       "10  Virtusa Consulting Services Pvt Ltd    2-4 Yrs   \n",
       "\n",
       "                                             Location  \n",
       "1                                 Bangalore/Bengaluru  \n",
       "2                                 Bangalore/Bengaluru  \n",
       "3                                 Bangalore/Bengaluru  \n",
       "4                                 Bangalore/Bengaluru  \n",
       "5                                 Bangalore/Bengaluru  \n",
       "6                                 Bangalore/Bengaluru  \n",
       "7                                 Bangalore/Bengaluru  \n",
       "8                                 Bangalore/Bengaluru  \n",
       "9   Hyderabad/Secunderabad, Bangalore/Bengaluru, D...  \n",
       "10                                Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JobDF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com/' \n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"ed4442f9bb411feab1dd51a0b309e3d8\", element=\"ec7d8fac-f8a0-4c96-8fe3-f60fbd8280d1\")>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobsearch = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "jobsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobsearch.send_keys(\"Data Scientist\")\n",
    "location = driver.find_element_by_id('qsb-location-sugg')\n",
    "location.send_keys(\"Bangalore\")\n",
    "search = driver.find_element_by_class_name('btn')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "company = []\n",
    "locations = []\n",
    "desc_url = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tag = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "company_tag = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "location_tag = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span[1]\")\n",
    "description_url = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in title_tag:\n",
    "    job_title.append(i.text)\n",
    "for c in company_tag:\n",
    "    company.append(c.text)\n",
    "company\n",
    "for l in location_tag:\n",
    "    locations.append(l.text)\n",
    "for u in description_url:\n",
    "    desc_url.append(u.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.naukri.com/job-listings-data-scientist-flipkart-internet-private-limited-bangalore-bengaluru-3-to-6-years-081021906627?src=jobsearchDesk&sid=16338414032903263&xp=1&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-ai-flagship-schneider-electric-india-pvt-ltd-bangalore-bengaluru-4-to-7-years-081021501357?src=jobsearchDesk&sid=16338414032903263&xp=2&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-glaxosmithkline-pharmaceuticals-limited-bangalore-bengaluru-4-to-7-years-081021501507?src=jobsearchDesk&sid=16338414032903263&xp=3&px=1',\n",
       " 'https://www.naukri.com/job-listings-sr-data-scientist-bizviz-technologies-private-limited-bangalore-bengaluru-4-to-7-years-081021002595?src=jobsearchDesk&sid=16338414032903263&xp=4&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-bd-bangalore-bengaluru-2-to-5-years-091021500390?src=jobsearchDesk&sid=16338414032903263&xp=5&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-applied-materials-india-private-limited-chennai-bangalore-bengaluru-7-to-10-years-081021909146?src=jobsearchDesk&sid=16338414032903263&xp=6&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-lead-data-scientist-scienaptic-systems-bangalore-bengaluru-10-to-12-years-041021500239?src=jobsearchDesk&sid=16338414032903263&xp=7&px=1',\n",
       " 'https://www.naukri.com/job-listings-lead-data-scientist-siemens-limited-bangalore-bengaluru-6-to-11-years-081021500651?src=jobsearchDesk&sid=16338414032903263&xp=8&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-odessa-technologies-bangalore-bengaluru-5-to-7-years-081021500769?src=jobsearchDesk&sid=16338414032903263&xp=9&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-machine-learning-engineer-python-sql-spark-axcess-consultancy-services-hyderabad-secunderabad-pune-chennai-gurgaon-gurugram-bangalore-bengaluru-3-to-8-years-081021903174?src=jobsearchDesk&sid=16338414032903263&xp=10&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-immediate-joiners-atg-business-solutions-private-limited-bangalore-bengaluru-5-to-7-years-150921007902?src=jobsearchDesk&sid=16338414032903263&xp=11&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-o9-solutions-management-india-private-limited-bangalore-bengaluru-2-to-4-years-081021005444?src=jobsearchDesk&sid=16338414032903263&xp=12&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-novotree-minds-consulting-pvt-ltd-bangalore-bengaluru-3-to-6-years-081021500067?src=jobsearchDesk&sid=16338414032903263&xp=13&px=1',\n",
       " 'https://www.naukri.com/job-listings-hiring-senior-data-scientist-new-era-india-consultancy-pvt-ltd-pune-ahmedabad-bangalore-bengaluru-delhi-ncr-2-to-7-years-081021004960?src=jobsearchDesk&sid=16338414032903263&xp=14&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-advanced-analytics-ibm-india-pvt-limited-bangalore-bengaluru-5-to-10-years-051021909207?src=jobsearchDesk&sid=16338414032903263&xp=15&px=1',\n",
       " 'https://www.naukri.com/job-listings-digital-enterprise-architect-data-scientist-mphasis-limited-bangalore-bengaluru-10-to-13-years-051021900146?src=jobsearchDesk&sid=16338414032903263&xp=16&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-intel-technology-india-pvt-ltd-bangalore-bengaluru-1-to-2-years-041021501560?src=jobsearchDesk&sid=16338414032903263&xp=17&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-kwalee-india-pvt-ltd-bangalore-bengaluru-5-to-10-years-260321000780?src=jobsearchDesk&sid=16338414032903263&xp=18&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-applied-materials-india-private-limited-bangalore-bengaluru-2-to-4-years-081021909686?src=jobsearchDesk&sid=16338414032903263&xp=19&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-allegis-services-india-pvt-ltd-bangalore-bengaluru-1-to-3-years-071021604773?src=jobsearchDesk&sid=16338414032903263&xp=20&px=1']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in desc_url:\n",
    "    driver.get(d)\n",
    "    try:\n",
    "        content= driver.find_element_by_xpath(\"//div[@class='dang-inner-html']\").text.replace('\\n',\" \").replace('\\n\\n',\" \")\n",
    "        \n",
    "        desc.append(content)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['About the role A Data Scientist in Flipkart is required to develop and implement a mix of ML, statistical and optimization models for the various projects formulated from business and product views. The responsible person should be able to communicate and collaborate with multiple stakeholders representing various teams to better understand the problem at hand. At a fundamental level, the responsible person should be able to dive deep into a problem statement and extract interesting insights as well as solutions. In addition to being a quick learner, a DS is expected to get involved in active research projects with a view to publish them. What you ll do Understand Business and product needs and use ML, statistical and optimization techniques as appropriate to provide solutions to those in a time bound fashion. Communicate and collaborate with business and product teams to have a better understanding of the project so as to be able to drive it within the DS team. Get involved in in-depth exploration of solutions that are to be shared with business and product teams; specifically, build models and scalable custom algorithms for problems including decision optimization and predictive modeling. Active participation in working with new methods and learning new technologies, in areas including data science and data engineering. What you ll need: B.Tech, M.Tech or PhD in CS, Operations Research or related discipline with professional experience ranging from 3 to 6 years through deployed solutions/projects. Candidate should have taken academic coursework in Operations Research (specifically mathematical optimization) Demonstrated experience in building discrete, linear, nonlinear or stochastic optimization models is required. Experience with optimization models for supply chain optimization is preferred but not required Demonstrated experience in utilizing and tuning commercial optimization solvers (e.g. CPLEX, Gurobi) and in building custom optimization algorithms (e.g. exact algorithms, metaheuristics, large neighborhood search, decomposition algorithms, greedy/randomized search) for industry-scale problems is required. Good grasp on the theory and practise of basic statistical models such as regression or clustering and general ML algorithms such as tree, Random Forests, SVM, Boosting, Neural Networks etc. It is not expected that the candidate has actually worked on all these modules. Strong proficiency in Python or R is necessary.',\n",
       " 'Identify and understand business problems : partner with business stakeholders to understand and communicate on business objectives Define analytical techniques to solve business challenges Provide data science contribution into the assigned projects Be part of the innovation programs (eg. Semtech, chatbots) Maintain high quality code and documentation Assure efficiency, stability and scalability of the solution Create deliver easily-consumable presentations to large groups of stakeholders and executives that showcase actionable insights and recommendations Team Interaction Data Scientist interacts with all members of service line she is assigned to in order to develop provide best in class solutions for the business. She interacts as well with key stakeholders of the business domain business process owners/experts, operations etc. in order to identify business opportunities, discuss test solutions She interacts also with other service lines as well as Analytics Apps Infrastructure team in order to exchange best practices She interacts also with Analytics Apps Infrastructure team in order to industrialize data products She interacts with Global IT department (Schneider Digital) to support the work on Intel Data Store    ',\n",
       " 'Working with multidisciplinary teams to identify, validate, and source required data and tools to develop and mature ML capabilities Performing data mining to discover nonobvious relationships, building training data, implementing and retraining ML solutions Conducting discovery workshops with business partners to identify business problems Building visualization dashboards to present metrics, statistical findings, and progress tracking Your Responsibilities Collaborate and work across business units to identify and source the data and technology to build and mature ML capabilities Conduct discovery workshops with business partners to identify business problems, obtain and validate training data Design, Build, implement, and retrain ML models to solve specific business problems Perform data mining and apply findings to increase modeling accuracy Cleary and concisely communicate business needs, computational findings and recommendations to all audiences regardless of their background or technical understanding Build, implement, and maintain visualization dashboards that clearly present both historical and real time operational metrics, research findings, and progress updates Basic Qualifications Bachelors degree in Applied Mathematics, Mathematical Engineering, Computer Science, Information Technology, or Related Field 10 + years of overall technical experience 2+ years of Machine Learning and or Data Mining experience 2+ years of experience building visualization dashboards 2+ years working with and manipulating large data sets 2+ years of hands on development experience using multiple languages Preferred Qualifications Masters degree in Applied Mathematics, Mathematical Engineering, Computer Science, Information Technology, or Related Field Experience with tools such as Tableau and Power BI Experience manipulating large data sets using technologies such as Hadoop, Azure, Hive, Spark, Element, Data Bricks, Mongo, and BigQuery Strong development experience using multiple languages such as Python, R Studio, SQL, C#, Java, Java Script, and Julia Successful completion of 2 or more projects (end to end) involving the migration and merging of large data sets from multiple sources, leveraging statistical analysis to identify meaningful and significant data relationships to build, train, and retrain ML models Experience and/or exposure to the cyber security industry and working with a SIEM such as Splunk or Google Chronicle',\n",
       " 'As a data scientist, you need to be exceptionally driven, curious and creative. You will work with data scientists, engineers and product managers to create new ideas, formulate mathematical algorithms, design new machine learning models and develop prototype solutions to enhance capabilities of our products and satisfaction from our customers. You need to be an exceptional problem solver and have great communication skill.  Responsibilities:  Work on complex and extremely varied data sets Build algorithms based on telematics data and geographical information Build products Work with the Data Engineering team to productionise and optimise the models Design, build, and deploy internal tools and processes to operationalise ML best practices within our productata tasks Sharpen our data science capacity by mentoring team members on building predictive models, experimental methodologies, and causal inference approaches Develop and foster collaborative relationships with product, business and engineering teams to effectively serve our customers needs.  Specifications:  Degree or demonstrable experience in a quantitative field like statistics, physics, applied mathematics, operations research or engineering. Advanced degrees are preferred. Industry experience in data science, with statistics and machine learning responsibilities Experience with a range of techniques from statistical modelling to deep learning, from linear models to neural networks Proficiency in Python and SQL Experience developing and productionising models Experience with ML frameworks such as TensorFlow, Keras, Spark, Theano etc Strong background in Linear Algebra, Statistics and Mathematics Experience working with public cloud, preferably AWS or Azure Experience handling large datasets (>billions of rows) Exceptional communication skills and the ability to simplify complex engineering notions to non-technical audience Natural problem solver with curiosity as a feature, not a bug Ability to set expectations and confidently talk to AI hype versus reality Experience working cross functionally with engineering and product teams in a collaborative environment  Bonus points: Experience working with telematics data Experience working on automotive use cases Knowledge and understanding of geographical information systems and related data ecosystem Stream processing and real-time analytics',\n",
       " '  Understand business problems and develop end-to-end data science use cases Collaborate across the function to understand data and to find ways to visualize and communicate your work to both technical and non-technical audiences. Evolve best data operational practices and maintain all compliance requirements Monitor data science models in production Actively network on a regular basis with SME to better understand the business/technical mechanics that generated the data Promote collaboration and knowledge exchange with other data science teams within and outside the organization Develop processes and tools to monitor and analyze model performance and data accuracy One or more scientific programming languages such as R, Python, or Julia, One or more database query languages such as SQL, or HiveQL, One or more general-purpose scripting languages such as Bash, PowerShell, or Perlrovide the total years of experience and the relevant experience required in the relevant field for this position Skills Technical / Functional Skills Behavioural Skills Soft Skills Leadership Skills',\n",
       " 'We are looking for an energetic and experienced person as Sr/Lead Data Scientist. The chosen candidate will be responsible for interacting with clients and developing all aspects of data mining, predictive analytic, solution development to name a few. Requirements Lead and take part in end-to-end ML (Machine Learning) projects deployments that require feasibility analysis, design, development, validation, and application of state-of-the art data science solutions. Need to deliver solutions to production through the software development lifecycle. You will have to push the state of the art application in terms of data mining, visualization, predictive modelling, statistics, trend analysis, and other data analysis techniques to solve complex business problems including recommender systems, Customer sentiment modelling, customer life-cycle modelling, Spare parts inventory optimization, spare parts pricing, warranty, After market channel effectiveness. Write production ready code and deploy real time ML models; expose ML outputs through APIs. Hypothesis Testing and Design of experiments to analyze and monitor results Partner with Data/ML engineers and vendor partners for input data pipes development and ML models automation. Skills 5 10 years of Applied Machine learning experience in the fields of Machine Learning, Recommender Systems, Statistical Modelling, Predictive Modelling. Note: We are looking for candidates who are presently serving their notice or who can join us within 15-20 days.',\n",
       " 'This is your role. What part will you play You will be responsible for design and development of AI/ML solutions based on customer requirements within the constraints of architectural / design guidelines Involved in customer discussions for requirement engineering and developing solution architecture You will mine and analyze data from multiple data sources to drive optimization, reduce cost and improve other business outcomes. Regular technical coordination / review with customers and ensuring timely reporting and issues if any We don’t need hard workers, just super minds You must have BE / B.Tech / MCA / ME / M.Tech qualification with confirmed ability building with 8-11 years of experience in design and development. Proficiency with analytics, mathematics, and statistical analysis with significant hands-on experience in AI / Data Science. Must have very strong confirmed knowledge of data science AI technologies and associated frameworks. Hands-on working experience in   Time Series Data ,   Machine Learning, Deep learning . Should be involved in any combination of Probabilistic Data analysis or Classification Algorithm/Predictions/ Fault Prediction/Statistical Modeling /Time Series Modeling/Linear Regression Modeling/ Anomaly Detection Class of any domain specific data!, Good understanding in frameworks like shiny, Dplyr, Ggplot2, Esquisse, NumPy, SciPy, Pandas etc. Knowledge in: Linear and logistic regression, K-means, K-medoids, Naive Bayes, Decision tree, Random forest, Clustering, Bayesian model, PCA, LDA, t-SNE, LSTM, CNN, Predictive modelling, Time Series Analysis and Forecasting, Natural Language Processing (NLP) and Tabular Data set Must have good understanding of different Cloud Systems, knowledge of AWS Cloud and AWS services is must to have. Experience in data visualization tools like Tableau, Power BI, working with and creating data architectures. Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks. Good knowledge of querying SQL No SQL databases. Knowledge and experience in statistical and analytics techniques: GLM/Regression, Random Forest, Boosting, Trees, SVM, text mining, social network analysis, etc. Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, MySQL, etc. Confirmed experience as a Data Scientist or Data Analyst Experience, Understanding of machine-learning and operations research. Visualizing/presenting the data analysis to partners in MS power point using following libraries ggplot, matplotlib, Seaborn. Experience in developing deploying the end-to-end data science pipeline into production.',\n",
       " '  Primary Role Odessa is looking for an experienced data scientist to drive high-quality design, execution, and development of analytical solutions that solve for complex business problems. As a data scientist, you will be responsible for developing features that rely on insights garnered by analyzing information and transactional data in the product database. The ideal candidate will be experienced in utilizing large datasets to identify new insights and opportunities for product and process optimization as well as using models to test the effectiveness of recommended processes and procedures. In this role, you will serve as a key stakeholder and thought leader in the evolution of Odessa s overall AI offering, working cross-functionally with technology leadership, functional teams and wide range of stakeholders to drive the long-term product roadmap. He/she will constantly look for opportunities in Odessa s overall AI offering to drive innovation, leveraging industry best practices to add value to the customer journey in our solution suite.  What you ll do Work closely with stakeholders across the organization to identify opportunities to leverage product data to drive business solutions Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques, and business strategies Use predictive modeling to increase and optimize customer experiences, process optimization, financial fraud detection, business event prediction, and other business outcomes Assess effectiveness and accuracy of new data sources and data gathering techniques Develop custom data models and algorithms to apply to data sets Drive testing strategy for AI initiatives and test model quality Coordinate with functional and technical teams to understand, implement, and help design the optimal technical solutions Develop processes and tools to monitor and analyze model performance and data accuracy  Basic qualifications Bachelor s or Master s Degree in Statistics, Mathematics, Computer Science, or equivalent quantitative field 5-7 years of experience manipulating data sets and building statistical models, and is familiar with the following software/tools: Coding knowledge and experience with several languages: C, C++, Java, JavaScript, etc. Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc. Experience querying databases and using statistical computer languages: R, Python, SLQ, etc. Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc. Experience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc. Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc. Strong problem-solving skills with an emphasis on product development Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets Experience working with and creating data architectures Knowledge of multiple machine learning techniques including clustering, decision tree learning, artificial neural networks, etc., their real-world advantages and/or drawbacks Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, and proper usage, etc.) and experience with applications Proven ability to drive business results with data-based insights Excellent written and verbal communication skills to work collaboratively and sucessfully coordinate across teams Preferred qualifications Experience building AI-related features in enterprise-grade solutions in the BFSI space Hands-on experience with the usage of emerging technologies (Azure or AWS AI/ML services)',\n",
       " 'Designation:  Project Tech. Lead (4A): 5 - 7 Years  Project Manager/Architect (4B/5A): 7 - 10 Years  Role and responsibilities  - Project Management (50%)  - Design, develop, deploy, and maintain production-grade scalable data transformation, machine learning and deep learning code, pipelines; manage data and model versioning, training, tuning, serving, experiment and evaluation tracking dashboards.  - Manage ETL and machine learning model lifecycle: develop, deploy, monitor, maintain, and update data and models in production.  - Build and maintain tools and infrastructure for data processing for AI/ML development initiatives.  Technical skills requirements : The candidate must demonstrate proficiency in :  - Experience deploying machine learning models into production environment.  - Strong DevOps, Data Engineering and ML background with Cloud platforms  - Experience in containerization and orchestration (such as Docker, Kubernetes)  - Experience with ML training/retraining, Model Registry, ML model performance measurement using ML Ops open source frameworks.  - Experience building/operating systems for data extraction, ingestion and processing of large data sets  - Experience with MLOps tools such as MLFlow and Kubeflow  - Experience in Python scripting  - Experience with CI/CD  - Fluency in Python data tools e.g. Pandas, Dask, or Pyspark  - Experience working on large scale, distributed systems  - Python/Scala for data pipelines  - Scala/Java/Python for micro-services and APIs  - HDP, Oracle skills & Sql; Spark, Scala, Hive and Oozie DataOps (DevOps, CDC)  Nice-to-have skills  - Jenkins, K8S  - Google Cloud certification  - Unix or Shell scripting',\n",
       " 'Position/Title: Data Scientist Department: IT Level: 3/4 Location: Bangalore  About ATG  Founded in 2012, ATG is a global services company providing technology, business process management and consulting services to some of the leading global organizations. We have a proven track record of helping our clients identify and deliver significant bottom line improvements using our expertise in finance, legal, HR and information technology related services. Our unique business engagement model is purpose-built to offer our client partners with best-in-class service through dedicated resources such as people, technology, infrastructure and top management support.  For more information, log on to http://www.aeriestechnology.com  About the role  We are looking for a savvy Data Engineer/Scientist to join our team. This candidate will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced Data Engineer who has grown into a Data Scientist. The Data Engineer/Scientist will support our software developers, architects, data analysts on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.  Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions. Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies. Assess the effectiveness and accuracy of new data sources and data gathering techniques. Develop custom data models and algorithms to apply to data sets. Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes. Develop company A/B testing framework and test model quality. Coordinate with different functional teams to implement models and monitor outcomes. Develop processes and tools to monitor and analyze model performance and data accuracy.   About you Strong problem-solving skills with an emphasis on product development. Experience using statistical computer languages (R, Python, SQL, etc.) to manipulate data and draw insights from large data sets. Experience working with and creating data architectures. Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks. Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications. Excellent written and verbal communication skills for coordinating across teams. A drive to learn and master new technologies and techniques. Were looking for someone with 5-7 years of experience manipulating data sets and building statistical models, has a Masters in Statistics, Mathematics, Computer Science or another quantitative field. Coding knowledge and experience with several languages: C, C++, Java, JavaScript, etc. Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc. Experience querying databases and using statistical computer languages: R, Python, SLQ, etc. Experience using web services: Redshift, S3, Spark, etc. Experience creating and using advanced machine learning, algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc. Experience analyzing data from 3rd party providers: Google Analytics, Crimson Hexagon, Facebook Insights, etc. Experience visualizing/presenting data for stakeholders using different tools. Working knowledge of message queuing (Kafka or Google Pub/Sub), stream processing, and highly scalable data stores.  Interested candidate may share their updated resume to jyoti.kumar@aeriestechnology.com with the below details: CTC: Expected CTC: Notice Period: Current Location: Reason for leaving: Please list down 5 - 10 skills for data analysis: Comfortable working in Bangalore location:',\n",
       " 'What youll do for us  Analyze problems by synthesizing complex information, evaluating alternate methods, and articulating the result with the relevant assumptions/reasons Apply a variety of machine learning techniques (clustering, regression, ensemble learning, neural nets, time series, optimizations etc.) to their real-world advantages/drawbacks to develop or optimize planning solutions Actively monitor, validate, root cause and tune statistical, time series, ML, optimization models Optimise, scale & deploy ML models using o9s open big data cloud platform Evaluate/test additional data streams, parameters, algorithms to enhance models post go-live and develop new models to improve existing ones Responsible for solution usability and uptime by resolving any customer issues in a timely fashion, ensuring accuracy of inputs and outputs Identify any design issues in the existing model and co-ordinate with other o9 consultants and data sceintists to solve the business problem. Be the single point of contact for any platform level upgrade/patch/hot fix. Work with customer data science teams and support Super User and End User training, for a global user base.  What youll have  Mandatory: 2+ years of experience in the field of Data Science and Analytics. Data Scientist or Sr Data Scientist will be decided based on experience, knowledge, and interview performance. Strong programming skills and experience in using Python and/or R for Data Science Strong analytical techniques, data mining knowledge and proficiency in handling and processing large amounts of data is needed Deep Knowledge of statistical and machine learning algorithms Experience in maintenance and/or building of scalable ML frameworks by identifying and collecting relevant input data, feature engineering, tuning, and testing. Strong presentation and communications skills Bachelors Degree in Computer Science, Mathematics, Statistics, Economics, Engineering or related field  Nice to have: Experience in time series forecasting in scale using heuristic-based hierarchical best-fit models using algorithms like exponential smoothing, ARIMA, prophet and custom parameter tuning Experience in applied analytical methods in the field of Supply chain and planning, like demand planning, demand sensing, supply planning, market intelligence, optimal assortments/pricing/inventory etc. Experience with SQL, databases and ETL tools or similar is optional but preferred Exposure to distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, or related Big Data technologies Experience with Deep Learning frameworks such as Keras, Tensorflow or PyTorch is preferable but not essential Experience in implementing planning applications will be a plus Understanding of Supply Chain Concepts will be preferable  What well do for you Competitive salary       Exposure: Work with the biggest brands in the world in an international environment Get social: When we work from home, we play from home with fun after-work activities like Friday Socials. If youre in the office, feel free to join these events in person. Flat organization: With a very strong entrepreneurial culture (and no corporate politics). Support network: Work with a team you can learn from and every day. Diversity: We pride ourselves on our international working environment.   How the process works Apply by clicking the button below. You’ll be contacted by our recruiter, who’ll fill you in on all things at o9, give you some background about the role and get to know you. They’ll contact you either via video call or phone call - whatever you prefer. You may be required to take an online data science test During the interview phase, you will meet with technical panels for 60 minutes. The recruiter will contact you after the interview to let you know if we’d like to progress your application. We will have 3 rounds of Technical discussion followed by an HR discussion Our recruiter will let you know if you’re the successful candidate.  Good luck!',\n",
       " 'Role involves 60% individual contribution, 25% customer engagement and 15% project managemen Lead individual projects on their own end to end,effortlessly switching between roles of an Individual Contributor, team member and Project Manager as demanded by each project Work closely with project team, Customer stakeholders and internal Business Units in devising creative analytical approaches to solve business problems Enhancing existing models, build new ones and maintain all models along with developing and updating code and process documentation Demonstrated analytic, quantitative, and programming skills Proficiency in a structured programming language is a must knowledge of one of statistical/general purpose scripting languages software such as R, SAS, Python, Java etc. is mandatory. Strong SQL, Microsoft Excel, VBA (preferred), Access and PowerPoint skills Experience in conducting quantitative analyses and interpreting results Excellent written and verbal communication skills Organized, structured and reliable while being an effective problem solver 3-6 years of relevant big data and analytics experience including hands-on programming in one (or more) of the above languages. Minimum 5 years spent with Analytics teams of reputed consultants and IT/ITES companies doing statistical modelling using above tools Tech from Tier-1 college (IITs, NITs, IIITs etc.)',\n",
       " 'Hi  Hiring Data Scientist (Only immediate joiner / one month notice period) Hands on with Deep learning ,ML,Python,AI',\n",
       " 'Uses predictive modeling, statistics, Machine Learning, Data Mining, and other data analysis techniques to collect, explore, and extract insights from structure and unstructured data . Develop software, algorithms and applications to apply mathematics to data, perform large scale experimentation and build data driven apps to translate data into intelligence, solve a variety of business problems and enable business strategy.  Assists business with casual inferences observations with finding patterns , relationships in data. Must possess strong understanding of internal business segment (stakeholders) and possess strong written and communication skills. Typically requires expertise in relational database structures, research methods, machine learning, Cloud based technologies, Big Data technologies (i.e. Hadoop , HBase, Lucene/Solr), analytics packages (i.e. R, Mahout, Matlab, Octave, Weka), scripting languages (i.e. Python, Perl), programing languages (i.e. Java, C/C , SQL). Typically possesses advanced degree in Computer Science, Mathematics, Machine Learning, Operation Research, and Statistics or equivalent expertise.   Minimum qualifications are required to be initially considered for this position. Preferred qualifications are in addition to the minimum requirements and are considered a plus factor in identifying top candidates.  Minimum Qualifications: <',\n",
       " 'Kwalee is one of the world\\'s leading multiplatform game publishers, with well over 600 million downloads worldwide for mobile hits such as Draw It, Teacher Simulator, Lets Be Cops 3D and Makeover Studio 3D. Alongside this, we also have a growing PC and console team of incredible pedigree that is on the hunt for great new titles to join TENS! and Eternal Hope.  With a team of talented people collaborating daily between our studios in Leamington Spa, Bangalore and Beijing, or on a remote basis from Turkey, Brazil, the Philippines and many more, we have a truly global team making games for a global audience. And its paying off: Kwalee games have been downloaded in every country on earth! If you think you\\'re a good fit for one of our remote vacancies, we want to hear from you wherever you are based.  Founded in 2011 by David Darling CBE, a key architect of the UK games industry who previously co-founded and led Codemasters for many years, our team also includes legends such as Andrew Graham (creator of Micro Machines series) and Jason Falcus (programmer of classics including NBA Jam) alongside a growing and diverse team of global gaming experts. Everyone contributes creatively to Kwalees success, with all employees eligible to pitch their own game ideas on Creative Wednesdays, and we’re proud to have built our success on this inclusive principle. Could your idea be the next global hit?  As a Senior Data Scientist you will help utilise masses of data generated by Kwalee players all over the world to solve complex problems using cutting edge techniques. You\\'ll be part of a team that will be based in the new office that we\\'re going to open in Bangalore. What you tell your friends you do \"My models optimise the performance of Kwalee games and advertising every day!”  What you will really be doing Build data solutions to solve business problems Use statistical testing and predictive modelling to recommend and implement changes to marketing strategy along with in game features and design Leverage the huge amount of data generated by our players and advertising campaigns everyday to build models and iterate existing services to improve and automate decision making across the company Work with the marketing, publishing and development teams to understand the problems they are facing and how to solve them  How you will be doing this You’ll be part of an agile, multidisciplinary and creative team and work closely with them to ensure the best results. You\\'ll think creatively and be motivated by challenges and constantly striving for the best. You’ll work with cutting edge technology, if you need software or hardware to get the job done efficiently, you can get it. We even have a robot!  Team Our talented team is our signature. We have a highly creative atmosphere with more than 150 staff where you’ll have the opportunity to contribute daily to important decisions. You’ll work within an extremely experienced, passionate and diverse team, including David Darling and the creator of the Micro Machines video games.  Skills and requirements A degree in a numerically focussed degree discipline such as, Maths, Physics, Economics, Chemistry, Engineering, Biological Sciences 5+Years experience using Python for data analysis and visualisation and using libraries such as Tensorflow, Keras and Scikit-Learn A proven track record of solving problems with data Knowledge of NoSQL or SQL databases like Couchbase, Elasticsearch and PostgreSQL An avid interest in the development, marketing and monetisation of mobile games  Desirable Experience with AWS - Redshift, EC2, Lambda Experience managing data projects from prototype to production tools  We offer We want everyone involved in our games to share our success, that’s why we have a generous team profit sharing scheme from day 1 of employment In addition to a competitive salary we also offer private medical cover and life assurance Creative Wednesdays! (Design and make your own games every Wednesday) 20 days of paid holidays plus bank holidays Great work-life balance with flexible working hours Quarterly team building days - work hard, play hard! Monthly employee awards Free snacks, fruit and drinks  Our philosophy We firmly believe in creativity and innovation and that a fundamental requirement for a successful and happy company is having the right mix of individuals. With the right people in the right environment anything and everything is possible.',\n",
       " 'Job Description: Responsibilities: Own and execute end to end delivery of one or more than one analytics project Understand requirements from Product Managers/Business Users Translating muddy and fuzzy business needs into clear analytical problems through structured problem-solving Extract data from multiple data sources, develop predictive models using appropriate variables and ML/deep learning techniques and operationalize the models on a BI platform for end users consumption Validate the models developed against statistical robustness and business sense Perform ad-hoc deep dive analysis proactively / based on stated needs Generate insights based on the data patterns and recommend actions to be taken by the business; Communicate the results to technical as well as business stakeholders across different hierarchies Create technical documentation and provide post-production support for a time-bound period Primary skillset: End to end data science project life cycles from use case framing, data collection, data exploration, model building to deployment Good knowledge in statistics and deep understanding on ML algorithms and their usage (Time series, Regression, Classification, Clustering, Anomaly Detection, NLP etc.) Secondary skillset: Deep expertise in analytical tools: At least one of the statistical computing language (R, Python, Tensorflow, Keras etc.) At least one of the query language (T-SQL, PLSQL, Hive, Spark, Impala, Cassandra, MongoDB etc.). Knowledge of big data is essential At least one of the reporting/visualization tools (Tableau, QlikView, SSRS, Power BI, D3, Angular JS etc.) Proven record of successfully building and operationalizing variety of machine learning solutions Experience level: 01yrs-02yrs']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc2 = []\n",
    "for d in desc_url:\n",
    "    driver.get(d)\n",
    "    try:\n",
    "        content= driver.find_element_by_xpath(\"//div[@class='clearboth description']\").text.replace('\\n',\" \").replace('\\n\\n',\" \")\n",
    "        \n",
    "        desc2.append(content)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['At Applied Materials, we are building the next generation fab productivity solutions using Artificial Intelligence and Machine Learning. Our AI/ML team is looking for a Data Scientist who will be responsible for building predictive and prescriptive models to increase and optimize fab productivity. The data scientist must be self-directed and independent in conducting their work as well as working with and supporting globally distributed teams. The right candidate will be excited by the prospect of building our company’s next generation data science practice and products. Responsibilities Formulate and lead guided, multifaceted analytic studies against large volumes of data. Interpret and analyze data using exploratory mathematic and statistical techniques based on the scientific method. Coordinate research and analytic activities utilizing various data points (unstructured and structured) and employ programming to clean, massage, and organize the data. Experiment against data points, provide information based on experiment results and provide previously undiscovered solutions to command data challenges. Develop, productize and maintain machine learning and optimization models according to requirements to transform our product into an innovative industry leader Analyze problems and determines root causes. Work with stakeholders including the Product management, Data and Design teams to build models. Support our customers with their data science and optimization problems using our product Qualifications Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Experience working with ‘big data’ data pipelines, architectures and data sets. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Strong analytic skills related to working with unstructured datasets. A successful history of manipulating, processing and extracting value from large disconnected datasets. Strong project management and organizational skills. Experience supporting and working with cross-functional teams in a dynamic environment. Experience with big data tools: Hadoop, Spark, Kafka, etc. Experience with relational SQL and NoSQL databases, including Postgres, Cassandra, MongoDB. Experience with cloud AI services from AWS, Google, Azure Experience with optimization tools: Gurobi, CPLEX, etc. Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc. Education/Experience Candidate with 6+ years of experience in a Data Scientist role, who has attained a Graduate degree in Operations Research, Computer Science, Statistics, Informatics, Information Systems or another quantitative field.   Qualifications Education:Bachelors DegreeSkillsCertifications:Languages:Years of Experience:7 - 10 YearsWork Experience:  Additional Information Travel:Yes, 10% of the TimeRelocation Eligible:Yes',\n",
       " 'As a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether it s investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.  Your Role and Responsibilities Work with IBM Q Start team on active exploratory research engagements to prepare for future use case commercialization within specific industry Engage and educate client data science teams to define promising areas for quantum exploration Implement quantum approaches, which includes data pre-/post-processing, running numerics and visualizing data Collaborate with industry and solutioning experts to design and shape experiments to demonstrate quantum-enabled advantage Define best practices related to information architecture, including collection, integration, organization, analysis and visualization of data for quantum-enabled impact Engage in practice development initiatives focused on building employee knowledge and skills in specific areas of expertise through coaching and development of training course material Required Technical and Professional Expertise PhD/Masters in STEM-related fields with knowledge in Quantum Computing. 5 years of data engineering and data science experience 2 years of consulting experience within specific industries with strong domain expertise and business acumen Proficiency with classical approaches to machine learning and linear algebra, including Support Vector Machine (SVM) for linear categorization and Singular Value Decomposition (SVD) to reduce dimensionality of data Familiar with Qiskit software, including Qiskit Aqua for domain applications and Qiskit Terra for quantum circuit design and optimization Excellent ideation, facilitation and communications skills Detail-oriented team player with strong interpersonal skills and ability to take a leadership role when necessary Willingness to travel globally up to 40% once we return to a travel-safe environment. English: Fluent Preferred Technical and Professional Expertise 2 years of experience in at least one of the industries, with knowledge of industry trends, R&D areas, and computationally intensive processes (e.g. optimization) Familiarity with Qiskit',\n",
       " 'We are looking for applicants who will thrive in an open, dynamic, flexible, collaborative environment and desire creative freedom and an opportunity to work with high performing teams, who can join in 15 to 20 days. We are looking for a Data Scientist that will help us discover the information hidden in vast amounts of data for our client projects and help us derive cognitive based solutions for. Your primary focus will be in applying data mining techniques, doing statistical analysis and building high quality prediction systems integrated with our solutions like Automate scoring using machine learning techniques”, “build recommendation systems”, “improve and extend the features used by our existing classifier”, “develop internal A/B testing procedures”, “build system for automated fraud detection”, etc. Responsibilities: Selecting features, building and optimizing classifiers using machine learning techniques Data mining using state-of-the-art methods Extending company’s data with third party sources of information when needed Enhancing data collection procedures to include information that is relevant for building analytic systems Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of its performance Understands the Data science methodologies to the existing enterprise services to bring in the cognitive edge as the differentiators Skills & Qualifications: Solid knowledge of several statistical modeling and learning techniques. Hands on Coding in Azure Databricks, PySparks, Azure AI/ML services and Python/R Expertise in use of algorithmic / quantitative techniques to solve problems across following four areas Structured data analysis and programming Unstructured content mining Natural language processing Machine learning Experience in Azure platform (good to have) Technically hands-on experience in Azure Machine Learning services, Azure ML Studio, Azure Cognitive toolkit, designing, building and training machines etc., Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc. Experience with common data science toolkits, such as Anaconda, NumPy, MatLab, Pandas, Seaborn, SciKit-Learn, NLTK, etc . Excellence in at least one of these is highly desirable Great communication skills Experience with data visualization tools, such as D3.js, GGplot, etc. Good applied statistics skills, such as distributions, statistical testing, regression, etc. Good scripting and programming skills Proficiency in using query languages such as SQL, Hive, Pig etc., Experience with NoSQL databases, such as MongoDB, Cassandra, HBase Experience working with enterprise architecture for the complex solutions solving business problems and complying to organization policies Master of Technology in Data Science specialization',\n",
       " 'Technical Skills and Experience Candidates must have 3+ years of R programming experience with mastery in Shiny R programming Skills and shiny web app development. Design and Building shiny web apps using R programming on VM. Worked on R packages like Data.Table, dplyr, tidry, Ggplot2 among others. Automate reporting and provide interactivity using R and Shiny. Knowledge of JavaScript, experience in developing HTML widget packages, fluency in CSS, Virtual Machine, Jira, ShellScript, Proficiency in understanding of code versioning using Git Experience extracting, combining, and conditioning various data formats from multiple sources using shellScript Other Skills A demonstrated end to end project experience Has technical documentation skill Capitalizes on opportunities to pursue value. Brings issues out in the open so that all concerns can address and find solutions. Strong interpersonal skills, with an ability to do customer interactions. Independent worker with high attention to detail Has an open and learning mindset. Adapts to new learning approaches and methods. Building professional relationships with team members and customers Functional Knowledge Demonstrates conceptual and practical expertise in own discipline and basic knowledge of related disciplines Business Expertise Has knowledge of coding best practices Leadership Acts as a resource for colleagues with less experience; may lead small projects with manageable risks and resource requirements Problem Solving Solves complex problems; takes a new perspective on existing solutions; exercises judgment based on the analysis of multiple sources of information Impact Impacts a range of customer, operational, project or service activities within own team and other related teams; works within broad guidelines and policies Interpersonal Skills Explains difficult or sensitive information; works to build consensus   Qualifications Education:Bachelors DegreeSkillsCertifications:Languages:Years of Experience:2 - 4 YearsWork Experience:  Additional Information Travel:Yes, 20% of the TimeRelocation Eligible:Yes']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc2 #last 2 descriptions are in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = [] #combining values of desc1 and desc2 into main 'descriptions' list\n",
    "for i in range(0,8):\n",
    "    descriptions.append(desc[i])\n",
    "for j in range(0,2):\n",
    "    descriptions.append(desc2[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing in JobDF Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "JobDF = pd.DataFrame({\"Job Title\":job_title[0:10],\"Company\":company[0:10],\"Location\":locations[0:10],\"Job Description\":descriptions[0:10]})\n",
    "JobDF.reset_index(drop=True,inplace = True)\n",
    "JobDF.index+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>About the role A Data Scientist in Flipkart is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - AI Flagship</td>\n",
       "      <td>Schneider Electric India Pvt. Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Identify and understand business problems : pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Working with multidisciplinary teams to identi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>BIZVIZ TECHNOLOGIES PRIVATE LIMITED</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>As a data scientist, you need to be exceptiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>bd</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Understand business problems and develop end...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>We are looking for an energetic and experience...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior/Lead Data Scientist</td>\n",
       "      <td>Scienaptic Systems</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>This is your role. What part will you play You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Siemens Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Primary Role Odessa is looking for an experi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Odessa Technologies</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>At Applied Materials, we are building the next...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist / Machine Learning Engineer - P...</td>\n",
       "      <td>Axcess consultancy services</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Gurgaon...</td>\n",
       "      <td>As a Data Scientist at IBM, you will help tran...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job Title  \\\n",
       "1                                      Data Scientist   \n",
       "2                        Data Scientist - AI Flagship   \n",
       "3                                      Data Scientist   \n",
       "4                                  Sr. Data Scientist   \n",
       "5                                      Data Scientist   \n",
       "6                                      Data Scientist   \n",
       "7                          Senior/Lead Data Scientist   \n",
       "8                                 Lead Data Scientist   \n",
       "9                                      Data Scientist   \n",
       "10  Data Scientist / Machine Learning Engineer - P...   \n",
       "\n",
       "                                    Company  \\\n",
       "1         Flipkart Internet Private Limited   \n",
       "2        Schneider Electric India Pvt. Ltd.   \n",
       "3   GlaxoSmithKline Pharmaceuticals Limited   \n",
       "4       BIZVIZ TECHNOLOGIES PRIVATE LIMITED   \n",
       "5                                        bd   \n",
       "6                         Applied Materials   \n",
       "7                        Scienaptic Systems   \n",
       "8                           Siemens Limited   \n",
       "9                       Odessa Technologies   \n",
       "10              Axcess consultancy services   \n",
       "\n",
       "                                             Location  \\\n",
       "1                                 Bangalore/Bengaluru   \n",
       "2                                 Bangalore/Bengaluru   \n",
       "3                                 Bangalore/Bengaluru   \n",
       "4                                 Bangalore/Bengaluru   \n",
       "5                                 Bangalore/Bengaluru   \n",
       "6                        Chennai, Bangalore/Bengaluru   \n",
       "7                                 Bangalore/Bengaluru   \n",
       "8                                 Bangalore/Bengaluru   \n",
       "9                                 Bangalore/Bengaluru   \n",
       "10  Hyderabad/Secunderabad, Pune, Chennai, Gurgaon...   \n",
       "\n",
       "                                      Job Description  \n",
       "1   About the role A Data Scientist in Flipkart is...  \n",
       "2   Identify and understand business problems : pa...  \n",
       "3   Working with multidisciplinary teams to identi...  \n",
       "4   As a data scientist, you need to be exceptiona...  \n",
       "5     Understand business problems and develop end...  \n",
       "6   We are looking for an energetic and experience...  \n",
       "7   This is your role. What part will you play You...  \n",
       "8     Primary Role Odessa is looking for an experi...  \n",
       "9   At Applied Materials, we are building the next...  \n",
       "10  As a Data Scientist at IBM, you will help tran...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JobDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  You have to use the location and salary filter.\n",
    "####  You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "####  You have to scrape the job-title, job-location, company_name, experience_required.\n",
    "####  The location filter to be used is “Delhi/NCR”\n",
    "####  The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com/' \n",
    "driver.get(url)\n",
    "\n",
    "jobsearch = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "jobsearch\n",
    "jobsearch.send_keys(\"Data Scientist\")\n",
    "search = driver.find_element_by_class_name('btn')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_filter=driver.find_element_by_xpath(\"//span[@title='Delhi / NCR']\")\n",
    "location_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_filter=driver.find_element_by_xpath(\"//span[@title='3-6 Lakhs']\")\n",
    "salary_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "company = []\n",
    "locations = []\n",
    "xp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tag = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "company_tag = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "location_tag = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span[1]\")\n",
    "xp_tag = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "\n",
    "for i in title_tag:\n",
    "    job_title.append(i.text)\n",
    "for c in company_tag:\n",
    "    company.append(c.text)\n",
    "company\n",
    "for l in location_tag:\n",
    "    locations.append(l.text)\n",
    "for x in xp_tag:\n",
    "    xp.append(x.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing in JobDF Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "JobDF = pd.DataFrame({\"Job Title\":job_title[0:10],\"Company\":company[0:10],\"Experience\":xp[0:10],\"Location\":locations[0:10]})\n",
    "JobDF.reset_index(drop=True,inplace = True)\n",
    "JobDF.index+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist I/II/III</td>\n",
       "      <td>OLX India Pvt Ltd</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Milliman India Pvt Ltd</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Academic Counsellor - Data Scientist</td>\n",
       "      <td>GreatLearning</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "      <td>Noida, Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist I/II/III</td>\n",
       "      <td>OLX, Inc</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Job Opportunity || Data Scientist || HCL Techn...</td>\n",
       "      <td>HCL Technologies</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>lericon infomatics pvt.ltd</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Mumbai, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NatWest Group</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job Title  \\\n",
       "1                             Data Scientist I/II/III   \n",
       "2                                      Data Scientist   \n",
       "3                Academic Counsellor - Data Scientist   \n",
       "4                                      Data Scientist   \n",
       "5                             Data Scientist I/II/III   \n",
       "6   Job Opportunity || Data Scientist || HCL Techn...   \n",
       "7                            Associate Data Scientist   \n",
       "8                                      Data Scientist   \n",
       "9                                      Data Scientist   \n",
       "10                                     Data Scientist   \n",
       "\n",
       "                                           Company Experience  \\\n",
       "1                                OLX India Pvt Ltd    3-6 Yrs   \n",
       "2                           Milliman India Pvt Ltd    2-5 Yrs   \n",
       "3                                    GreatLearning    1-4 Yrs   \n",
       "4   Optum Global Solutions (India) Private Limited    2-6 Yrs   \n",
       "5                                         OLX, Inc    3-6 Yrs   \n",
       "6                                 HCL Technologies    4-7 Yrs   \n",
       "7   Optum Global Solutions (India) Private Limited    2-7 Yrs   \n",
       "8                       lericon infomatics pvt.ltd    3-5 Yrs   \n",
       "9                                    NatWest Group    2-7 Yrs   \n",
       "10                               Fractal Analytics    3-7 Yrs   \n",
       "\n",
       "                                         Location  \n",
       "1                                Gurgaon/Gurugram  \n",
       "2                                Gurgaon/Gurugram  \n",
       "3           Gurgaon/Gurugram, Bangalore/Bengaluru  \n",
       "4                         Noida, Gurgaon/Gurugram  \n",
       "5                                Gurgaon/Gurugram  \n",
       "6                                     Delhi / NCR  \n",
       "7                                           Noida  \n",
       "8                             Mumbai, Delhi / NCR  \n",
       "9                                Gurgaon/Gurugram  \n",
       "10  Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JobDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.glassdoor.co.in/index.htm' \n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "key1 = driver.find_element_by_xpath('//button[@class=\"d-none d-lg-block p-0 LockedHomeHeaderStyles__signInButton\"]')\n",
    "key1.click()\n",
    "time.sleep(2)\n",
    "key2 =  driver.find_element_by_id('userEmail')\n",
    "key2.send_keys('dpk92249@gmail.com')\n",
    "time.sleep(2)\n",
    "key3 = driver.find_element_by_id('userPassword')\n",
    "key3.send_keys('9693655358')\n",
    "clk1 = driver.find_element_by_xpath('//button[@class=\"gd-ui-button minWidthBtn css-8i7bc2\"]')\n",
    "clk1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "key4 = driver.find_element_by_id('sc.keyword')\n",
    "key4.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.keys import Keys\n",
    "key4 = driver.find_element_by_id('sc.location')\n",
    "key4.send_keys(Keys.CONTROL,'a')\n",
    "key4.send_keys(Keys.BACKSPACE)\n",
    "time.sleep(1)\n",
    "key4.send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ad = driver.find_element_by_xpath('/html/body/div[8]/div/div[2]/span')\n",
    "    ad.click()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name = [] \n",
    "posted = []\n",
    "Rating_company = []\n",
    "\n",
    "company = driver.find_elements_by_xpath('//a[@class=\"  job-search-key-l2wjgv e1n63ojh0 jobLink\"]')\n",
    "for i in company:\n",
    "    company_name.append(i.text)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "post = driver.find_elements_by_xpath('//div[@class=\"d-flex align-items-end pl-std css-mi55ob\"]')\n",
    "\n",
    "for i in post:\n",
    "    posted.append(i.text)\n",
    "    \n",
    "time.sleep(5)\n",
    "\n",
    "rating = driver.find_elements_by_xpath('//span[@class=\"css-19pjha7 e1cjmv6j1\"]')\n",
    "for i in rating:\n",
    "    Rating_company.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>posted</th>\n",
       "      <th>Rating_company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [company_name, posted, Rating_company]\n",
       "Index: []"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glass_door = pd.DataFrame({})\n",
    "glass_door['company_name'] = company_name [:10]\n",
    "glass_door['posted'] = posted[:10]\n",
    "glass_door['Rating_company'] = Rating_company[:10]\n",
    "glass_door.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location. You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.glassdoor.co.in/Salaries/index.htm' \n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobsearch = driver.find_element_by_id('KeywordSearch')\n",
    "jobsearch\n",
    "jobsearch.send_keys(\"Data Scientist\")\n",
    "location = driver.find_element_by_id('LocationSearch')\n",
    "location.send_keys(\"Noida\")\n",
    "search = driver.find_element_by_xpath('/html/body/div[3]/div/div[1]/div[1]/div/div/form/button')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = []\n",
    "job_title = []\n",
    "Rating = []\n",
    "sals = []\n",
    "avg_sal = []\n",
    "sal_num = []\n",
    "Rating_tag = driver.find_elements_by_xpath(\"//span[@class='m-0 css-kyx745']\")\n",
    "company_tag = driver.find_elements_by_xpath(\"//a[@class='css-f3vw95 e1aj7ssy3']\")\n",
    "title_tag = driver.find_elements_by_xpath(\"//div[@class='col-12 col-lg px-xsm']//span\")\n",
    "sal_num_tag = driver.find_elements_by_xpath(\"//div[@class='col-12 col-lg-auto']//span\")\n",
    "sals_tag = driver.find_elements_by_xpath(\"//div[@class='d-none d-lg-block']//p\")\n",
    "avg_sal_tag = driver.find_elements_by_xpath(\"//div[@class='col-12 col-lg-4 px-lg-0 d-flex align-items-baseline']\")\n",
    "for i in company_tag:\n",
    "    company.append(i.text)\n",
    "for j in title_tag :\n",
    "    job_title.append(j.text)\n",
    "for r in Rating_tag:\n",
    "    Rating.append(r.text)\n",
    "for n in sal_num_tag:\n",
    "    sal_num.append(n.text)\n",
    "for m in sals_tag:\n",
    "    sals.append(m.text)\n",
    "for a in avg_sal_tag:\n",
    "    avg_sal.append(a.text.replace(\"\\n \",\"\"))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹6,31,184/yr',\n",
       " '₹9,08,246/yr',\n",
       " '₹12,13,338/yr',\n",
       " '₹7,61,766/yr',\n",
       " '₹12,49,716/yr',\n",
       " '₹12,80,000/yr',\n",
       " '₹12,42,519/yr',\n",
       " '₹12,70,000/yr',\n",
       " '₹11,71,868/yr',\n",
       " '₹14,55,430/yr',\n",
       " '₹11,40,187/yr',\n",
       " '₹8,86,064/yr',\n",
       " '₹9,62,227/yr',\n",
       " '₹20,63,782/yr',\n",
       " '₹11,01,815/yr',\n",
       " '₹12,40,275/yr',\n",
       " '₹50,000/mo',\n",
       " '₹14,51,902/yr',\n",
       " '₹6,87,316/yr',\n",
       " '₹5,91,319/yr']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_sal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹4L',\n",
       " '₹13L',\n",
       " '₹1L',\n",
       " '₹28L',\n",
       " '₹6L',\n",
       " '₹23L',\n",
       " '₹4L',\n",
       " '₹17L',\n",
       " '₹5L',\n",
       " '₹1Cr',\n",
       " '₹8L',\n",
       " '₹16L',\n",
       " '₹6L',\n",
       " '₹20L',\n",
       " '₹8L',\n",
       " '₹20L',\n",
       " '₹2L',\n",
       " '₹22L',\n",
       " '₹10L',\n",
       " '₹18L',\n",
       " '₹6L',\n",
       " '₹21L',\n",
       " '₹5L',\n",
       " '₹15L',\n",
       " '₹4L',\n",
       " '₹13L',\n",
       " '₹10L',\n",
       " '₹46L',\n",
       " '₹4L',\n",
       " '₹21L',\n",
       " '₹6L',\n",
       " '₹17L',\n",
       " '₹25T',\n",
       " '₹1L',\n",
       " '₹10L',\n",
       " '₹21L',\n",
       " '₹4L',\n",
       " '₹15L',\n",
       " '₹2L',\n",
       " '₹23L']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separating min and max salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sal =[]\n",
    "max_sal = []\n",
    "\n",
    "for i in range(0,len(sals),2):\n",
    "    min_sal.append(sals[i])\n",
    "for j in range(1,len(sals),2):\n",
    "    max_sal.append(sals[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹4L',\n",
       " '₹1L',\n",
       " '₹6L',\n",
       " '₹4L',\n",
       " '₹5L',\n",
       " '₹8L',\n",
       " '₹6L',\n",
       " '₹8L',\n",
       " '₹2L',\n",
       " '₹10L',\n",
       " '₹6L',\n",
       " '₹5L',\n",
       " '₹4L',\n",
       " '₹10L',\n",
       " '₹4L',\n",
       " '₹6L',\n",
       " '₹25T',\n",
       " '₹10L',\n",
       " '₹4L',\n",
       " '₹2L']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_sal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹13L',\n",
       " '₹28L',\n",
       " '₹23L',\n",
       " '₹17L',\n",
       " '₹1Cr',\n",
       " '₹16L',\n",
       " '₹20L',\n",
       " '₹20L',\n",
       " '₹22L',\n",
       " '₹18L',\n",
       " '₹21L',\n",
       " '₹15L',\n",
       " '₹13L',\n",
       " '₹46L',\n",
       " '₹21L',\n",
       " '₹17L',\n",
       " '₹1L',\n",
       " '₹21L',\n",
       " '₹15L',\n",
       " '₹23L']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing in JobDF Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Minimum Salary(₹)</th>\n",
       "      <th>Maximum Salary(₹)</th>\n",
       "      <th>Average Salary(₹)</th>\n",
       "      <th>Number of Salaries</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹4L</td>\n",
       "      <td>₹13L</td>\n",
       "      <td>₹6,31,184/yr</td>\n",
       "      <td>25 salaries</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IBM</td>\n",
       "      <td>₹1L</td>\n",
       "      <td>₹28L</td>\n",
       "      <td>₹9,08,246/yr</td>\n",
       "      <td>20 salaries</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹23L</td>\n",
       "      <td>₹12,13,338/yr</td>\n",
       "      <td>16 salaries</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>₹4L</td>\n",
       "      <td>₹17L</td>\n",
       "      <td>₹7,61,766/yr</td>\n",
       "      <td>15 salaries</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>₹5L</td>\n",
       "      <td>₹1Cr</td>\n",
       "      <td>₹12,49,716/yr</td>\n",
       "      <td>15 salaries</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>₹8L</td>\n",
       "      <td>₹16L</td>\n",
       "      <td>₹12,80,000/yr</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>EXL Service</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹20L</td>\n",
       "      <td>₹12,42,519/yr</td>\n",
       "      <td>11 salaries</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Optum</td>\n",
       "      <td>₹8L</td>\n",
       "      <td>₹20L</td>\n",
       "      <td>₹12,70,000/yr</td>\n",
       "      <td>11 salaries</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>₹2L</td>\n",
       "      <td>₹22L</td>\n",
       "      <td>₹11,71,868/yr</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>₹10L</td>\n",
       "      <td>₹18L</td>\n",
       "      <td>₹14,55,430/yr</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Job Title                    Company Minimum Salary(₹)  \\\n",
       "1   Data Scientist  Tata Consultancy Services               ₹4L   \n",
       "2   Data Scientist                        IBM               ₹1L   \n",
       "3   Data Scientist                  Accenture               ₹6L   \n",
       "4   Data Scientist         Ericsson-Worldwide               ₹4L   \n",
       "5   Data Scientist                  Delhivery               ₹5L   \n",
       "6   Data Scientist         UnitedHealth Group               ₹8L   \n",
       "7   Data Scientist                EXL Service               ₹6L   \n",
       "8   Data Scientist                      Optum               ₹8L   \n",
       "9   Data Scientist              ZS Associates               ₹2L   \n",
       "10  Data Scientist     Optum Global Solutions              ₹10L   \n",
       "\n",
       "   Maximum Salary(₹) Average Salary(₹) Number of Salaries Rating  \n",
       "1               ₹13L      ₹6,31,184/yr        25 salaries    3.9  \n",
       "2               ₹28L      ₹9,08,246/yr        20 salaries    3.9  \n",
       "3               ₹23L     ₹12,13,338/yr        16 salaries    4.1  \n",
       "4               ₹17L      ₹7,61,766/yr        15 salaries      4  \n",
       "5               ₹1Cr     ₹12,49,716/yr        15 salaries    3.7  \n",
       "6               ₹16L     ₹12,80,000/yr        14 salaries    3.7  \n",
       "7               ₹20L     ₹12,42,519/yr        11 salaries    3.6  \n",
       "8               ₹20L     ₹12,70,000/yr        11 salaries    3.7  \n",
       "9               ₹22L     ₹11,71,868/yr        10 salaries      4  \n",
       "10              ₹18L     ₹14,55,430/yr        10 salaries    3.9  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JobDF = pd.DataFrame({\"Job Title\":job_title[0:10],\"Company\":company[0:10],\"Minimum Salary(₹)\":min_sal[0:10],\"Maximum Salary(₹)\":max_sal[0:10],\"Average Salary(₹)\":avg_sal[0:10],\"Number of Salaries\":sal_num[0:10],\"Rating\":Rating[0:10]})\n",
    "JobDF.reset_index(drop=True,inplace = True)\n",
    "JobDF.index+= 1\n",
    "JobDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "#### 1. Brand\n",
    "#### 2. Product Description\n",
    "#### 3. Price\n",
    "#### 4. Discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.flipkart.com' \n",
    "driver.get(url)\n",
    "glassessearch = driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "glassessearch.send_keys(\"Sunglasses\")\n",
    "search = driver.find_element_by_class_name('L0Z3Pu')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = []\n",
    "desc = []\n",
    "price = []\n",
    "disc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_tag = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "price_tag = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "disc_tag = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")\n",
    "desc_tag = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "for b in brand_tag:\n",
    "        brand.append(b.text)\n",
    "for d in desc_tag :\n",
    "        desc.append(d.text)\n",
    "for p in price_tag:\n",
    "        price.append(p.text)\n",
    "for c in disc_tag:\n",
    "        disc.append(c.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "nextbtn = driver.find_element_by_class_name('_1LKTO3')\n",
    "while(i<2):\n",
    "    try:\n",
    "        nextbtn.click()\n",
    "    except:\n",
    "        pass\n",
    "    time.sleep(3) #to allow the page to load completely before scraping.\n",
    "    brand_tag = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    price_tag = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    disc_tag = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")\n",
    "    desc_tag = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    \n",
    "    for b in brand_tag:\n",
    "        try:\n",
    "            brand.append(b.text)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    for d in desc_tag :\n",
    "        try:\n",
    "            desc.append(d.text)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    for p in price_tag:\n",
    "        try:\n",
    "            price.append(p.text)\n",
    "        except:\n",
    "            pass\n",
    "    for c in disc_tag:\n",
    "        try:\n",
    "            disc.append(c.text)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    if 'inactive' in nextbtn.get_attribute('class'):\n",
    "        break;\n",
    "    \n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing in SunglassesDF DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SunglassesDF = pd.DataFrame({\"Brand Name\":brand[0:100],\"Price(₹)\":price[0:100],\"Discount\":disc[0:100],\"Description\":desc[0:100],})\n",
    "SunglassesDF.reset_index(drop=True,inplace = True)\n",
    "SunglassesDF.index+= 1\n",
    "SunglassesDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price(₹)</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹729</td>\n",
       "      <td>43% off</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹499</td>\n",
       "      <td>37% off</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹399</td>\n",
       "      <td>55% off</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>₹198</td>\n",
       "      <td>88% off</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Rectangular...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹200</td>\n",
       "      <td>87% off</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>₹399</td>\n",
       "      <td>73% off</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (55)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>IDEE</td>\n",
       "      <td>₹799</td>\n",
       "      <td>61% off</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (50)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹349</td>\n",
       "      <td>56% off</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>IDEE</td>\n",
       "      <td>₹979</td>\n",
       "      <td>60% off</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (59)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>₹479</td>\n",
       "      <td>76% off</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (88)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Brand Name Price(₹) Discount  \\\n",
       "1             Fastrack     ₹729  43% off   \n",
       "2             Fastrack     ₹499  37% off   \n",
       "3             Fastrack     ₹399  55% off   \n",
       "4    SHAAH COLLECTIONS     ₹198  88% off   \n",
       "5               PIRASO     ₹200  87% off   \n",
       "..                 ...      ...      ...   \n",
       "96           ROYAL SON     ₹399  73% off   \n",
       "97                IDEE     ₹799  61% off   \n",
       "98            Fastrack     ₹349  56% off   \n",
       "99                IDEE     ₹979  60% off   \n",
       "100          ROYAL SON     ₹479  76% off   \n",
       "\n",
       "                                           Description  \n",
       "1                UV Protection Aviator Sunglasses (58)  \n",
       "2     UV Protection Rectangular Sunglasses (Free Size)  \n",
       "3        UV Protection Wayfarer Sunglasses (Free Size)  \n",
       "4    UV Protection, Polarized, Mirrored Rectangular...  \n",
       "5                UV Protection Aviator Sunglasses (54)  \n",
       "..                                                 ...  \n",
       "96           UV Protection Rectangular Sunglasses (55)  \n",
       "97    Mirrored, UV Protection Wayfarer Sunglasses (50)  \n",
       "98   Gradient, UV Protection Wayfarer Sunglasses (F...  \n",
       "99           UV Protection Rectangular Sunglasses (59)  \n",
       "100         UV Protection Retro Square Sunglasses (88)  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SunglassesDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone.Scrape the data for first 100 reviews.\n",
    "#### 1. Rating\n",
    "#### 2. Review_summary\n",
    "#### 3. Full review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "url = 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace' \n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewall = driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div/div/div[5]/div/a/div/span')\n",
    "viewall.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_sum = []\n",
    "rating = []\n",
    "rev = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "    rev_sum_tag = driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "    rating_tag = driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "    rev_tag = driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "    for r in rev_sum_tag:\n",
    "        rev_sum.append(r.text)\n",
    "    for j in rating_tag :\n",
    "        rating.append(j.text)\n",
    "    for k in rev_tag:\n",
    "        rev.append(k.text.replace(\"\\n\",\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "nextbtn = driver.find_element_by_class_name('_1LKTO3')\n",
    "while(i<10):\n",
    "    try:\n",
    "        nextbtn.click()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    time.sleep(3) #to allow the page to load completely before scraping.\n",
    "    rev_sum_tag = driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "    rating_tag = driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "    rev_tag = driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "    for r in rev_sum_tag:\n",
    "        try:\n",
    "            rev_sum.append(r.text)\n",
    "        except:\n",
    "            pass\n",
    "    for j in rating_tag :\n",
    "        try:\n",
    "            rating.append(j.text)\n",
    "        except:\n",
    "            pass\n",
    "    for k in rev_tag:\n",
    "        try:\n",
    "            rev.append(k.text.replace(\"\\n\",\" \"))\n",
    "        except:\n",
    "            pass\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing values in iphoneDF Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iphoneDF = pd.DataFrame({\"Summary\":rev_sum[0:100],\"Full Review\":rev[0:100],\"Rating\":rating[0:100]})\n",
    "iphoneDF.reset_index(drop=True,inplace = True)\n",
    "iphoneDF.index+= 1\n",
    "iphoneDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Full Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money  The iPhone 11 of...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Best budget Iphone till date ❤️ go for it guys...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Iphone is just awesome.. battery backup is ver...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Excellent camera, good performance, no lag. Th...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>It’s been almost a month since I have been usi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Terrific</td>\n",
       "      <td>Really worth of money. i just love it. It is t...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Summary                                        Full Review  \\\n",
       "1              Brilliant  The Best Phone for the Money  The iPhone 11 of...   \n",
       "2         Simply awesome  Really satisfied with the Product I received.....   \n",
       "3       Perfect product!  Amazing phone with great cameras and better ba...   \n",
       "4    Best in the market!  Great iPhone very snappy experience as apple k...   \n",
       "5              Fabulous!  This is my first iOS phone. I am very happy wi...   \n",
       "..                   ...                                                ...   \n",
       "96     Worth every penny  Best budget Iphone till date ❤️ go for it guys...   \n",
       "97      Perfect product!  Iphone is just awesome.. battery backup is ver...   \n",
       "98        Simply awesome  Excellent camera, good performance, no lag. Th...   \n",
       "99     Worth every penny  It’s been almost a month since I have been usi...   \n",
       "100             Terrific  Really worth of money. i just love it. It is t...   \n",
       "\n",
       "    Rating  \n",
       "1        5  \n",
       "2        5  \n",
       "3        5  \n",
       "4        5  \n",
       "5        5  \n",
       "..     ...  \n",
       "96       5  \n",
       "97       5  \n",
       "98       5  \n",
       "99       5  \n",
       "100      5  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iphoneDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "#### You have to scrape 4 attributes of each sneaker :\n",
    "#### 1. Brand\n",
    "#### 2. Product Description\n",
    "#### 3. Price\n",
    "#### 4. discount %\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.flipkart.com' \n",
    "driver.get(url)\n",
    "Sneakerssearch = driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "Sneakerssearch.send_keys(\"Sneakers\")\n",
    "search = driver.find_element_by_class_name('L0Z3Pu')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = []\n",
    "desc = []\n",
    "price = []\n",
    "disc = []\n",
    "brand_tag = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "price_tag = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "disc_tag = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")\n",
    "desc_tag = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "for b in brand_tag:\n",
    "   brand.append(b.text)\n",
    "for d in desc_tag :\n",
    "   desc.append(d.text)\n",
    "for p in price_tag:\n",
    "   price.append(p.text)\n",
    "for c in disc_tag:\n",
    "   disc.append(c.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "i=0\n",
    "nextbtn = driver.find_element_by_class_name('_1LKTO3')\n",
    "while(i<2):\n",
    "    try:\n",
    "        nextbtn.click()\n",
    "    except:\n",
    "        pass\n",
    "    time.sleep(3) #to allow the page to load completely before scraping.\n",
    "    brand_tag = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    price_tag = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    disc_tag = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")\n",
    "    desc_tag = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    \n",
    "    for b in brand_tag:\n",
    "        try:\n",
    "            brand.append(b.text)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    for d in desc_tag :\n",
    "        try:\n",
    "            desc.append(d.text)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    for p in price_tag:\n",
    "        try:\n",
    "            price.append(p.text)\n",
    "        except:\n",
    "            pass\n",
    "    for c in disc_tag:\n",
    "        try:\n",
    "            disc.append(c.text)\n",
    "        except:\n",
    "            pass\n",
    "    if 'inactive' in nextbtn.get_attribute('class'):\n",
    "        break;\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing values in  SneakersDF Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price(₹)</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>₹299</td>\n",
       "      <td>76% off</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASTEROID</td>\n",
       "      <td>₹474</td>\n",
       "      <td>76% off</td>\n",
       "      <td>Original Luxury Branded Fashionable Men's Casu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>₹407</td>\n",
       "      <td>68% off</td>\n",
       "      <td>White Sneaker For Men Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>₹303</td>\n",
       "      <td>39% off</td>\n",
       "      <td>Birde Trendy Casual Shoes Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>₹426</td>\n",
       "      <td>78% off</td>\n",
       "      <td>411 Casual Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>India hub</td>\n",
       "      <td>₹383</td>\n",
       "      <td>56% off</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>zovim</td>\n",
       "      <td>₹436</td>\n",
       "      <td>60% off</td>\n",
       "      <td>Casuals, Canvas, Partywear Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>mannu</td>\n",
       "      <td>₹398</td>\n",
       "      <td>57% off</td>\n",
       "      <td>Unique &amp; Perfect Collection Combo Pack of 02 S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>₹211</td>\n",
       "      <td>46% off</td>\n",
       "      <td>Mens Canvas Shoes for boys (Black) Sneakers Fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>₹1,889</td>\n",
       "      <td>61% off</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Brand Name Price(₹) Discount  \\\n",
       "1       BRUTON     ₹299  76% off   \n",
       "2     ASTEROID     ₹474  76% off   \n",
       "3      Numenzo     ₹407  68% off   \n",
       "4        BIRDE     ₹303  39% off   \n",
       "5      Numenzo     ₹426  78% off   \n",
       "..         ...      ...      ...   \n",
       "96   India hub     ₹383  56% off   \n",
       "97       zovim     ₹436  60% off   \n",
       "98       mannu     ₹398  57% off   \n",
       "99      Chevit     ₹211  46% off   \n",
       "100       PUMA   ₹1,889  61% off   \n",
       "\n",
       "                                           Description  \n",
       "1        Modern Trendy Sneakers Shoes Sneakers For Men  \n",
       "2    Original Luxury Branded Fashionable Men's Casu...  \n",
       "3               White Sneaker For Men Sneakers For Men  \n",
       "4           Birde Trendy Casual Shoes Sneakers For Men  \n",
       "5                          411 Casual Sneakers For Men  \n",
       "..                                                 ...  \n",
       "96                                    Sneakers For Men  \n",
       "97         Casuals, Canvas, Partywear Sneakers For Men  \n",
       "98   Unique & Perfect Collection Combo Pack of 02 S...  \n",
       "99   Mens Canvas Shoes for boys (Black) Sneakers Fo...  \n",
       "100                                   Sneakers For Men  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SneakersDF = pd.DataFrame({\"Brand Name\":brand[0:100],\"Price(₹)\":price[0:100],\"Discount\":disc[0:100],\"Description\":desc[0:100],})\n",
    "SneakersDF.reset_index(drop=True,inplace = True)\n",
    "SneakersDF.index+= 1\n",
    "SneakersDF.shape\n",
    "SneakersDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9: Go to the link - https://www.myntra.com/shoes\n",
    "#### Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”,And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "url = 'https://www.myntra.com/shoes' \n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "colour_filter = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label\")\n",
    "colour_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_filter = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label\")\n",
    "price_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = []\n",
    "desc = []\n",
    "price = []\n",
    "price2 = []\n",
    "brand_tag = driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "price_tag = driver.find_elements_by_xpath(\"//div[@class='product-price']//span[1]\")\n",
    "desc_tag = driver.find_elements_by_xpath(\"//h4[@class='product-product']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in brand_tag:\n",
    "   brand.append(b.text)\n",
    "for d in desc_tag :\n",
    "   desc.append(d.text)\n",
    "for p in price_tag:\n",
    "   price.append(p.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "i=0\n",
    "nextbtn = driver.find_element_by_class_name('pagination-next')\n",
    "while(i<1):\n",
    "    try:\n",
    "        nextbtn.click()\n",
    "    except:\n",
    "        pass\n",
    "    time.sleep(3) #to allow the page to load completely before scraping.\n",
    "    brand_tag = driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "    price_tag = driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']//span[1]\")\n",
    "    desc_tag = driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "\n",
    "    \n",
    "    for b in brand_tag:\n",
    "        try:\n",
    "            brand.append(b.text)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    for d in desc_tag :\n",
    "        try:\n",
    "            desc.append(d.text)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    for p in price_tag:\n",
    "        try:\n",
    "            price.append(p.text)\n",
    "        except:\n",
    "            pass\n",
    "    if 'inactive' in nextbtn.get_attribute('class'):\n",
    "        break;\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rs. 10499Rs. 14999',\n",
       " 'Rs. 10499',\n",
       " 'Rs. 11199Rs. 15999',\n",
       " 'Rs. 11199',\n",
       " 'Rs. 11199Rs. 15999',\n",
       " 'Rs. 11199',\n",
       " 'Rs. 7999Rs. 9999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 10399Rs. 12999',\n",
       " 'Rs. 10399',\n",
       " 'Rs. 7999Rs. 9999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 8799Rs. 10999',\n",
       " 'Rs. 8799',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 7199Rs. 8999',\n",
       " 'Rs. 7199',\n",
       " 'Rs. 8099Rs. 8999',\n",
       " 'Rs. 8099',\n",
       " 'Rs. 11999Rs. 14999',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 8449Rs. 12999',\n",
       " 'Rs. 8449',\n",
       " 'Rs. 8449Rs. 12999',\n",
       " 'Rs. 8449',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 10999',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 7999Rs. 9999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 7199Rs. 8999',\n",
       " 'Rs. 7199',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 7195',\n",
       " 'Rs. 7773Rs. 8449',\n",
       " 'Rs. 7773',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 6999Rs. 9999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 10999',\n",
       " 'Rs. 7999Rs. 9999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 7999Rs. 9999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 8449Rs. 12999',\n",
       " 'Rs. 8449',\n",
       " 'Rs. 8999Rs. 9999',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 8799Rs. 10999',\n",
       " 'Rs. 8799',\n",
       " 'Rs. 7799Rs. 12999',\n",
       " 'Rs. 7799',\n",
       " 'Rs. 7199Rs. 7999',\n",
       " 'Rs. 7199',\n",
       " 'Rs. 10900',\n",
       " 'Rs. 10399Rs. 12999',\n",
       " 'Rs. 10399',\n",
       " 'Rs. 11199Rs. 13999',\n",
       " 'Rs. 11199',\n",
       " 'Rs. 7693Rs. 10990',\n",
       " 'Rs. 7693',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 8490',\n",
       " 'Rs. 7149Rs. 10999',\n",
       " 'Rs. 7149',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 12799Rs. 15999',\n",
       " 'Rs. 12799',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 11199Rs. 15999',\n",
       " 'Rs. 11199',\n",
       " 'Rs. 12999',\n",
       " 'Rs. 12999',\n",
       " 'Rs. 9599Rs. 15999',\n",
       " 'Rs. 9599',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 7799Rs. 12999',\n",
       " 'Rs. 7799',\n",
       " 'Rs. 7990',\n",
       " '',\n",
       " 'Rs. 7799Rs. 12999',\n",
       " 'Rs. 7799',\n",
       " '',\n",
       " 'Rs. 7990',\n",
       " '',\n",
       " 'Rs. 6999Rs. 9999',\n",
       " 'Rs. 6999',\n",
       " '',\n",
       " 'Rs. 6990',\n",
       " '',\n",
       " 'Rs. 11305Rs. 11900',\n",
       " 'Rs. 11305',\n",
       " '',\n",
       " 'Rs. 6999Rs. 9999',\n",
       " 'Rs. 6999',\n",
       " '',\n",
       " 'Rs. 11999',\n",
       " '',\n",
       " 'Rs. 7006Rs. 7149',\n",
       " 'Rs. 7006',\n",
       " '',\n",
       " 'Rs. 8990',\n",
       " '',\n",
       " 'Rs. 8999Rs. 9999',\n",
       " 'Rs. 8999',\n",
       " '',\n",
       " 'Rs. 8990',\n",
       " '',\n",
       " 'Rs. 10999',\n",
       " '',\n",
       " 'Rs. 7199Rs. 8999',\n",
       " 'Rs. 7199',\n",
       " '',\n",
       " 'Rs. 7499',\n",
       " '',\n",
       " 'Rs. 7490',\n",
       " '',\n",
       " 'Rs. 9999',\n",
       " '',\n",
       " 'Rs. 6990',\n",
       " '',\n",
       " 'Rs. 8999',\n",
       " '',\n",
       " 'Rs. 8999',\n",
       " '',\n",
       " 'Rs. 11049Rs. 16999',\n",
       " 'Rs. 11049',\n",
       " '',\n",
       " 'Rs. 7999',\n",
       " '',\n",
       " 'Rs. 8399Rs. 11999',\n",
       " 'Rs. 8399',\n",
       " '',\n",
       " 'Rs. 6990',\n",
       " '',\n",
       " 'Rs. 8999',\n",
       " '',\n",
       " 'Rs. 9599Rs. 11999',\n",
       " 'Rs. 9599',\n",
       " '',\n",
       " 'Rs. 11474Rs. 13499',\n",
       " 'Rs. 11474',\n",
       " '',\n",
       " 'Rs. 9990',\n",
       " '',\n",
       " 'Rs. 6990',\n",
       " '',\n",
       " 'Rs. 6990',\n",
       " '',\n",
       " 'Rs. 7039Rs. 10999',\n",
       " 'Rs. 7039',\n",
       " '',\n",
       " 'Rs. 6990',\n",
       " '',\n",
       " 'Rs. 7990',\n",
       " '',\n",
       " 'Rs. 13490',\n",
       " '',\n",
       " 'Rs. 7999',\n",
       " '',\n",
       " 'Rs. 7499',\n",
       " '',\n",
       " 'Rs. 8999',\n",
       " '',\n",
       " 'Rs. 6990',\n",
       " '',\n",
       " 'Rs. 9999',\n",
       " '',\n",
       " 'Rs. 8999',\n",
       " '',\n",
       " 'Rs. 9999',\n",
       " '',\n",
       " 'Rs. 10999',\n",
       " '',\n",
       " 'Rs. 10999',\n",
       " '',\n",
       " 'Rs. 11999',\n",
       " '',\n",
       " 'Rs. 6990',\n",
       " '',\n",
       " 'Rs. 9099Rs. 12999',\n",
       " 'Rs. 9099',\n",
       " '',\n",
       " 'Rs. 8990',\n",
       " '',\n",
       " 'Rs. 8994Rs. 14990',\n",
       " 'Rs. 8994',\n",
       " '',\n",
       " 'Rs. 7999Rs. 9999',\n",
       " 'Rs. 7999',\n",
       " '',\n",
       " 'Rs. 9999',\n",
       " '',\n",
       " 'Rs. 6999Rs. 9999',\n",
       " 'Rs. 6999']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price #has duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(\"\" in price) :\n",
    "    price.remove(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rs. 10499Rs. 14999',\n",
       " 'Rs. 10499',\n",
       " 'Rs. 11199Rs. 15999',\n",
       " 'Rs. 11199',\n",
       " 'Rs. 11199Rs. 15999',\n",
       " 'Rs. 11199',\n",
       " 'Rs. 7999Rs. 9999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 10399Rs. 12999',\n",
       " 'Rs. 10399',\n",
       " 'Rs. 7999Rs. 9999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 8799Rs. 10999',\n",
       " 'Rs. 8799',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 7199Rs. 8999',\n",
       " 'Rs. 7199',\n",
       " 'Rs. 8099Rs. 8999',\n",
       " 'Rs. 8099',\n",
       " 'Rs. 11999Rs. 14999',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 8449Rs. 12999',\n",
       " 'Rs. 8449',\n",
       " 'Rs. 8449Rs. 12999',\n",
       " 'Rs. 8449',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 10999',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 7999Rs. 9999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 7199Rs. 8999',\n",
       " 'Rs. 7199',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 7195',\n",
       " 'Rs. 7773Rs. 8449',\n",
       " 'Rs. 7773',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 6999Rs. 9999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 10999',\n",
       " 'Rs. 7999Rs. 9999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 7999Rs. 9999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 8449Rs. 12999',\n",
       " 'Rs. 8449',\n",
       " 'Rs. 8999Rs. 9999',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 8799Rs. 10999',\n",
       " 'Rs. 8799',\n",
       " 'Rs. 7799Rs. 12999',\n",
       " 'Rs. 7799',\n",
       " 'Rs. 7199Rs. 7999',\n",
       " 'Rs. 7199',\n",
       " 'Rs. 10900',\n",
       " 'Rs. 10399Rs. 12999',\n",
       " 'Rs. 10399',\n",
       " 'Rs. 11199Rs. 13999',\n",
       " 'Rs. 11199',\n",
       " 'Rs. 7693Rs. 10990',\n",
       " 'Rs. 7693',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 8490',\n",
       " 'Rs. 7149Rs. 10999',\n",
       " 'Rs. 7149',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 12799Rs. 15999',\n",
       " 'Rs. 12799',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 11199Rs. 15999',\n",
       " 'Rs. 11199',\n",
       " 'Rs. 12999',\n",
       " 'Rs. 12999',\n",
       " 'Rs. 9599Rs. 15999',\n",
       " 'Rs. 9599',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 7799Rs. 12999',\n",
       " 'Rs. 7799',\n",
       " 'Rs. 7990',\n",
       " 'Rs. 7799Rs. 12999',\n",
       " 'Rs. 7799',\n",
       " 'Rs. 7990',\n",
       " 'Rs. 6999Rs. 9999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 11305Rs. 11900',\n",
       " 'Rs. 11305',\n",
       " 'Rs. 6999Rs. 9999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 7006Rs. 7149',\n",
       " 'Rs. 7006',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 8999Rs. 9999',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 10999',\n",
       " 'Rs. 7199Rs. 8999',\n",
       " 'Rs. 7199',\n",
       " 'Rs. 7499',\n",
       " 'Rs. 7490',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 11049Rs. 16999',\n",
       " 'Rs. 11049',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 8399Rs. 11999',\n",
       " 'Rs. 8399',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 9599Rs. 11999',\n",
       " 'Rs. 9599',\n",
       " 'Rs. 11474Rs. 13499',\n",
       " 'Rs. 11474',\n",
       " 'Rs. 9990',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 7039Rs. 10999',\n",
       " 'Rs. 7039',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 7990',\n",
       " 'Rs. 13490',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 7499',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 10999',\n",
       " 'Rs. 10999',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 9099Rs. 12999',\n",
       " 'Rs. 9099',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 8994Rs. 14990',\n",
       " 'Rs. 8994',\n",
       " 'Rs. 7999Rs. 9999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 6999Rs. 9999',\n",
       " 'Rs. 6999']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing duplicate values\n",
    "j = 0\n",
    "for c in price:\n",
    "    if len(c) > 12:\n",
    "        del price[j]\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rs. 10499',\n",
       " 'Rs. 11199',\n",
       " 'Rs. 11199',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 10399',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 8799',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 7199',\n",
       " 'Rs. 8099',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 8449',\n",
       " 'Rs. 8449',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 10999',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 7199',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 7195',\n",
       " 'Rs. 7773',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 10999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 8449',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 8799',\n",
       " 'Rs. 7799',\n",
       " 'Rs. 7199',\n",
       " 'Rs. 10900',\n",
       " 'Rs. 10399',\n",
       " 'Rs. 11199',\n",
       " 'Rs. 7693',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 8490',\n",
       " 'Rs. 7149',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 12799',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 11199',\n",
       " 'Rs. 12999',\n",
       " 'Rs. 12999',\n",
       " 'Rs. 9599',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 7799',\n",
       " 'Rs. 7990',\n",
       " 'Rs. 7799',\n",
       " 'Rs. 7990',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 11305',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 7006',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 10999',\n",
       " 'Rs. 7199',\n",
       " 'Rs. 7499',\n",
       " 'Rs. 7490',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 11049',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 8399',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 9599',\n",
       " 'Rs. 11474',\n",
       " 'Rs. 9990',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 7039',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 7990',\n",
       " 'Rs. 13490',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 7499',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 10999',\n",
       " 'Rs. 10999',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 9099',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 8994',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 6999']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### storing the values in MyntraShoeDF DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price(₹)</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Rs. 10499</td>\n",
       "      <td>Leather Solid Loafers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Rs. 11199</td>\n",
       "      <td>Men Leather Loafers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Rs. 11199</td>\n",
       "      <td>Men Driving Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PUMA Motorsport</td>\n",
       "      <td>Rs. 7999</td>\n",
       "      <td>Unisex Scuderia Ferrari Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Rs. 10399</td>\n",
       "      <td>Men Jamming 2.0 Running Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Ruosh</td>\n",
       "      <td>Rs. 8990</td>\n",
       "      <td>Men Solid Leather Formal Monks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Rs. 8994</td>\n",
       "      <td>Men Leather Formal Slip-Ons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Rs. 7999</td>\n",
       "      <td>Unisex Textured Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Rs. 9999</td>\n",
       "      <td>Women Leather Pumps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Rs. 6999</td>\n",
       "      <td>Women Solid Leather Pumps</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Brand Name   Price(₹)                     Description\n",
       "1               ALDO  Rs. 10499           Leather Solid Loafers\n",
       "2               ALDO  Rs. 11199             Men Leather Loafers\n",
       "3               ALDO  Rs. 11199               Men Driving Shoes\n",
       "4    PUMA Motorsport   Rs. 7999   Unisex Scuderia Ferrari Shoes\n",
       "5               Puma  Rs. 10399   Men Jamming 2.0 Running Shoes\n",
       "..               ...        ...                             ...\n",
       "96             Ruosh   Rs. 8990  Men Solid Leather Formal Monks\n",
       "97              Geox   Rs. 8994     Men Leather Formal Slip-Ons\n",
       "98              Puma   Rs. 7999        Unisex Textured Sneakers\n",
       "99              Geox   Rs. 9999             Women Leather Pumps\n",
       "100             ALDO   Rs. 6999       Women Solid Leather Pumps\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyntraShoesDF = pd.DataFrame({\"Brand Name\":brand[0:100],\"Price(₹)\":price[0:100],\"Description\":desc[0:100],})\n",
    "MyntraShoesDF.reset_index(drop=True,inplace = True)\n",
    "MyntraShoesDF.index+= 1\n",
    "MyntraShoesDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10: Go to webpage https://www.amazon.in/\n",
    "#### Enter “Laptop” in the search field and then click the search icon.\n",
    "#### Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”\n",
    "#### attributes for each laptop:\n",
    "#### 1. title\n",
    "#### 2. Ratings\n",
    "#### 3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.amazon.in/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge(\"msedgedriver.exe\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "Laptopsearch = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "Laptopsearch.send_keys(\"Laptop\")\n",
    "search = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "i7_filter = driver.find_element_by_xpath('//span[text() = \"Intel Core i7\"]')\n",
    "i7_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "i9_filter =  driver.find_element_by_xpath('//span[text() = \"Intel Core i9\"]')\n",
    "i9_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = []\n",
    "price = []\n",
    "Rating = []\n",
    "Rating_tag = driver.find_elements_by_xpath(\"//span[@class='a-icon-alt']\")\n",
    "title_tag = driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "price_tag = driver.find_elements_by_xpath(\"//div[@class='sg-col-inner']//span[@class='a-price-whole']\")\n",
    "\n",
    "for i in title_tag:\n",
    "    title.append(i.text)\n",
    "    \n",
    "for r in Rating_tag :\n",
    "    Rating.append(r.get_attribute(\"innerHTML\"))\n",
    "    \n",
    "for p in price_tag:\n",
    "    price.append(p.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "del title[8] #deleting element with no price attribute to prevent price mismatch in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.3 out of 5 stars',\n",
       " '4.4 out of 5 stars',\n",
       " '3.3 out of 5 stars',\n",
       " '4.3 out of 5 stars',\n",
       " '4.2 out of 5 stars',\n",
       " '4.0 out of 5 stars',\n",
       " '3.3 out of 5 stars',\n",
       " '3.8 out of 5 stars',\n",
       " '4.4 out of 5 stars',\n",
       " '4.2 out of 5 stars',\n",
       " '4.4 out of 5 stars',\n",
       " '4.3 out of 5 stars',\n",
       " '4.0 out of 5 stars',\n",
       " '4.5 out of 5 stars',\n",
       " '4.4 out of 5 stars',\n",
       " '3.2 out of 5 stars',\n",
       " '4.2 out of 5 stars',\n",
       " '4.1 out of 5 stars',\n",
       " '3.6 out of 5 stars',\n",
       " '5.0 out of 5 stars',\n",
       " '4.1 out of 5 stars',\n",
       " '4.8 out of 5 stars',\n",
       " '4.0 out of 5 stars',\n",
       " '4.3 out of 5 stars',\n",
       " '4.4 out of 5 stars',\n",
       " '4.4 out of 5 stars',\n",
       " '4 Stars &amp; Up',\n",
       " '3 Stars &amp; Up',\n",
       " '2 Stars &amp; Up',\n",
       " '1 Star &amp; Up']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving as LaptopDf DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laptop Name</th>\n",
       "      <th>Price(₹)</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LG Gram Ultra-Light 11th Gen Core i7,16 GB RAM...</td>\n",
       "      <td>92,290</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td>84,990</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Life Digital Laptop 15.6-inch (39.62 cms) (Int...</td>\n",
       "      <td>24,990</td>\n",
       "      <td>3.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Pavilion (2021) Intel 11th Gen Core i7 14 i...</td>\n",
       "      <td>84,990</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>53,990</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Acer Nitro 5 11th Gen Intel Core i7-11800H 15....</td>\n",
       "      <td>89,990</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ASUS TUF Dash F15 (2021) 15.6-inch (39.62 cms)...</td>\n",
       "      <td>87,000</td>\n",
       "      <td>3.8 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td>84,990</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dell 14 (2021) i7-1195G7 2in1 Touch Screen Lap...</td>\n",
       "      <td>91,990</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lenovo Legion 5 10th Gen Intel Core i7-10750H ...</td>\n",
       "      <td>89,990</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Laptop Name Price(₹)  \\\n",
       "1   LG Gram Ultra-Light 11th Gen Core i7,16 GB RAM...   92,290   \n",
       "2   Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....   84,990   \n",
       "3   Life Digital Laptop 15.6-inch (39.62 cms) (Int...   24,990   \n",
       "4   HP Pavilion (2021) Intel 11th Gen Core i7 14 i...   84,990   \n",
       "5   Mi Notebook Horizon Edition 14 Intel Core i7-1...   53,990   \n",
       "6   Acer Nitro 5 11th Gen Intel Core i7-11800H 15....   89,990   \n",
       "7   ASUS TUF Dash F15 (2021) 15.6-inch (39.62 cms)...   87,000   \n",
       "8   Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....   84,990   \n",
       "9   Dell 14 (2021) i7-1195G7 2in1 Touch Screen Lap...   91,990   \n",
       "10  Lenovo Legion 5 10th Gen Intel Core i7-10750H ...   89,990   \n",
       "\n",
       "                Rating  \n",
       "1   4.3 out of 5 stars  \n",
       "2   4.4 out of 5 stars  \n",
       "3   3.3 out of 5 stars  \n",
       "4   4.3 out of 5 stars  \n",
       "5   4.2 out of 5 stars  \n",
       "6   4.0 out of 5 stars  \n",
       "7   3.8 out of 5 stars  \n",
       "8   4.4 out of 5 stars  \n",
       "9   4.4 out of 5 stars  \n",
       "10  4.0 out of 5 stars  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LaptopDF = pd.DataFrame({\"Laptop Name\":title[0:10],\"Price(₹)\":price[0:10],\"Rating\":Rating[0:10]})\n",
    "LaptopDF.reset_index(drop=True,inplace = True)\n",
    "LaptopDF.index+= 1\n",
    "LaptopDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
